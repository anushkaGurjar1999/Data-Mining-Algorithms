{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length, sepal_width, petal_length, petal_width\n",
      "Train set: 95\n",
      "Test set: 55\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-setosa', actual='Iris-setosa'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "> predicted='Iris-virginica', actual='Iris-virginica'\n",
      "Accuracy: 96.36363636363636%\n"
     ]
    }
   ],
   "source": [
    "'''KNN using random division of data (67% training, 33% testing), \n",
    "this program will generate predicted class, actual class of data and total accuracy of model. '''\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def loadDataset(sampleFile, splitRatio, trainingSet=[] , testSet=[]): #Split the data into training and testing set\n",
    "    print(\"sepal_length, sepal_width, petal_length, petal_width\")\n",
    "    with open(sampleFile) as csvfile:\n",
    "        fileData = csv.reader(csvfile) #fileData is an object\n",
    "        dataset = list(fileData)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y]) #converting string data into float\n",
    "            if random.random() < splitRatio:  #random.random(),returns next random floating point num in the range(0.0,1.0)\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "\n",
    "def euclideanDistance(instOne, instTwo, length): #Calculating the euclidean Distance between two instances \n",
    "    ecDistance = 0\n",
    "    for x in range(length): #Loop for all attributes of the set\n",
    "        ecDistance += pow((instOne[x] - instTwo[x]), 2)\n",
    "    return math.sqrt(ecDistance)\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):     #Calculating k nearest neighbour\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length) #Calculate distance test set from each training set\n",
    "        distances.append((trainingSet[x], dist)) #Stroing distance of each training set [whole list, distance]\n",
    "    distances.sort(key=operator.itemgetter(1)) \n",
    "    #constructs a callable that assumes an iterable object(list,tuple,set) as input, and fetches the nth element out of it.\n",
    "    neighbors = []\n",
    "    for x in range(k): #find nearest k \n",
    "        neighbors.append(distances[x][0]) #Storing all k nearby lists\n",
    "    #print(neighbors)\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}                    #A 2D dictionary which is storing {class label, count}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]    #Storing the class label, which is commonly at the end of the list\n",
    "        if response in classVotes: \n",
    "            classVotes[response] += 1  #Increment the class label as it is in KNN\n",
    "        else:\n",
    "            classVotes[response] = 1   #Create the class label with count one\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True) #Sort list based on counts\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def getAccuracy(testSet, predictions): #Predicting accuracy of test results\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]: #Check if predicted class and actual class is same\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    # prepare data\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    splitRatio = 0.67\n",
    "    loadDataset(r'C:\\Users\\shree\\Desktop\\notbook\\DM\\iris.data', splitRatio, trainingSet, testSet) #Spliting data into 2 parts 67%,33%\n",
    "    print('Train set: '+repr(len(trainingSet))) #Length of training data\n",
    "    print('Test set: '+repr(len(testSet)))      #Length of testing data\n",
    "    predictions=[] #predicted labels\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)  #finding neighbour\n",
    "        result = getResponse(neighbors)                       #store the relevent class label \n",
    "        predictions.append(result)\n",
    "        print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + repr(accuracy) + '%')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48487235580073074   0.6822872916926128   0.5062676582105694   0.9428042469555008   0.34628251283003264   0.47913600830119096   0.5898590580696208   0.5225355903132026   0.11222925483665813   0.15373725424730944   0.19567176779768358   0.8587078321785188   0.29778785074529635   0.39760317005611956   0.5574296307977408   0.954608929134144   0.11980485432292909   0.5701851855540312   0.33544672177781965   "
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    print(random.random(), end=\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length, sepal_width, petal_length, petal_width\n",
      "Number of test cases you want to enter : 1\n",
      "Enter data for Test Set[ 0 ]\n",
      "2\n",
      "3\n",
      "5\n",
      "6\n",
      "6.0\n",
      "Train set: 150\n",
      "Test set: 1\n",
      "> predicted='Iris-setosa'\n"
     ]
    }
   ],
   "source": [
    "'''USER INPUT KNN: when user enters the Test Data set, based on predefine data set we predict the class label of Test Set \n",
    "'''\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def loadDataset(sampleFile, trainingSet=[] , testSet=[]): #Split the data into training and testing set\n",
    "    with open(sampleFile) as csvfile:\n",
    "        fileData = csv.reader(csvfile) #fileData is an object\n",
    "        dataset = list(fileData)\n",
    "        #for k in dataset:\n",
    "            #print(\",\".join(k))\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y]) #converting string data into float\n",
    "            trainingSet.append(dataset[x])\n",
    "            \n",
    "def euclideanDistance(instOne, instTwo, length): #Calculating the euclidean Distance between two instances \n",
    "    ecDistance = 0\n",
    "    for x in range(length): #Loop for all attributes of the set\n",
    "        ecDistance += pow((instTwo[x] - instTwo[x]), 2)\n",
    "    return math.sqrt(ecDistance)\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):     #Calculating k nearest neighbour\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length) #Calculate distance test set from each training set\n",
    "        distances.append((trainingSet[x], dist)) #Stroing distance of each training set\n",
    "    distances.sort(key=operator.itemgetter(1)) \n",
    "    #constructs a callable that assumes an iterable object(list,tuple,set) as input, and fetches the nth element out of it.\n",
    "    neighbors = []\n",
    "    for x in range(k): #find nearest k \n",
    "        neighbors.append(distances[x][0]) #Storing all k nearby lists\n",
    "    #print(neighbors)\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}                    #A 2D dictionary which is storing {class label, count}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]    #Storing the class label, which is commonly at the end of the list\n",
    "        if response in classVotes: \n",
    "            classVotes[response] += 1  #Increment the class label as it is in KNN\n",
    "        else:\n",
    "            classVotes[response] = 1   #Create the class label with count one\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True) #Sort list based on counts\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def main():\n",
    "    # prepare data\n",
    "    print(\"sepal_length, sepal_width, petal_length, petal_width\")\n",
    "    size=int(input(\"Number of test cases you want to enter : \"))\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    for i in range(size):          #A for loop for row entries \n",
    "        a =[] \n",
    "        print(\"Enter data for Test Set[\",i,\"]\")\n",
    "        for j in range(4):         #A for loop for column entries (as there are 4 columns) \n",
    "            a.append(float(input())) \n",
    "        testSet.append(a)\n",
    "    for i in range(len(testSet)):\n",
    "        print(testSet[i][-1])\n",
    "    loadDataset(r'C:\\Users\\shree\\Desktop\\notbook\\DM\\iris.data',trainingSet, testSet) \n",
    "    print('Train set: '+repr(len(trainingSet))) #Length of training data\n",
    "    print('Test set: '+repr(len(testSet)))      #Length of testing data\n",
    "    predictions=[] #predicted labels\n",
    "    k = 3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)  #finding neighbour\n",
    "        result = getResponse(neighbors)                       #store the relevent class label \n",
    "        predictions.append(result)\n",
    "        print('> predicted=' + repr(result))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
